{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "customClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3j6v1ytiIHCbm60BRJtVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenny101/Custom-Image-Classifier/blob/main/customClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbwZEaULyUB"
      },
      "source": [
        "# Create a Neural Network Image Classifier in Minutes!\n",
        "For faster results, make sure your runtime is a GPU instance. To do this, simply:\n",
        "  1. Click 'Runtime' \n",
        "  2. Select 'Change runtime type'\n",
        "  3. Select 'GPU'\n",
        "  4. Click 'Save'\n",
        "\n",
        "Run steps 1-3. Note that more classes of image will require more time to download and train.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24hrVFyOJCRv"
      },
      "source": [
        "# Step 1: Installing Dependencies and Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d867-KO0jbJh"
      },
      "source": [
        "#Setup/Dependencies\n",
        "!pip install fastbook\n",
        "!pip install git+https://github.com/Joeclinton1/google-images-download.git\n",
        "\n",
        "\n",
        "#import libraries\n",
        "import fastbook\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "import urllib.request\n",
        "import os\n",
        "import IPython.display as display\n",
        "import ipywidgets as widgets\n",
        "from google_images_download import google_images_download\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jUAiy9ijmm3"
      },
      "source": [
        "# Step 2: User Input, Downloading the Data, and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWAVguk9jlxX"
      },
      "source": [
        "print(\"How many things would you like to classify?\")\n",
        "num_classify = int(input())\n",
        "\n",
        "classifiers = []\n",
        "for i in range(1,num_classify+1):\n",
        "  print(f\"Type item {i}:\")\n",
        "  item = str(input())\n",
        "  print(\"\\n\")\n",
        "  classifiers.append(item)\n",
        "\n",
        "#Downloading the Data\n",
        "from google_images_download import google_images_download\n",
        "response = google_images_download.googleimagesdownload()\n",
        "\n",
        "for counter, my_class in enumerate(classifiers):\n",
        "    arguments = {\"keywords\":my_class,\n",
        "                 \"limit\":100,\n",
        "                 \"silent_mode\":True,\n",
        "                 \"output_directory\":\"Datasets\",\n",
        "                 \"image_directory\":my_class,\n",
        "                 \"format\":\"jpg\"}\n",
        "    paths = response.download(arguments)\n",
        "\n",
        "'''\n",
        "Dataloader: Tells fastai:\n",
        "(1) What kind of data do we have\n",
        "(2) How to get a list of the images\n",
        "(3) How to label the images\n",
        "(4) How to create the validation set\n",
        "'''\n",
        "path = Path('Datasets')\n",
        "myData = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock), \n",
        "    get_items=get_image_files, \n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(128))\n",
        "dls = myData.dataloaders(path)\n",
        "\n",
        "# Data Augmentation: changes the perspectives and scaling of the image\n",
        "myData = myData.new(\n",
        "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
        "    batch_tfms=aug_transforms())\n",
        "dls = myData.dataloaders(path)\n",
        "\n",
        "print(\"Training your model. Please wait.\\n\")\n",
        "learn = cnn_learner(dls, resnet18, metrics=error_rate)\n",
        "learn.fine_tune(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCvBE2ejJaF-"
      },
      "source": [
        "# Step 3: Cleaning your dataset to produce more accurate results (Optional)\n",
        "Keep, delete, or recategorize an image manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqlpwL1qJiyl"
      },
      "source": [
        "cleaner = ImageClassifierCleaner(learn)\n",
        "cleaner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5EgD7K8Jz3J"
      },
      "source": [
        "# Step 4: Exporting your model and testing it on url image inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dek8H6D5rx5P"
      },
      "source": [
        "\n",
        "#export the model\n",
        "learn.export()\n",
        "path = Path()\n",
        "path.ls(file_exts='.pkl')\n",
        "learn_inf = load_learner('export.pkl')\n",
        "\n",
        "print('\\n Model exported as: \"export.pkl\". Feel free to download it for future use. \\n')\n",
        "\n",
        "#Download a query to a folder\n",
        "def downloadToDisplay(query, folder_name):\n",
        "\n",
        "    #Download a single image of query\n",
        "    arguments = {\"keywords\":query,\n",
        "                 \"limit\":1,\n",
        "                 \"silent_mode\":True,\n",
        "                 \"output_directory\":folder_name,\n",
        "                 \"format\":\"jpg\"}\n",
        "    paths = response.download(arguments)\n",
        "    \n",
        "    #Rename file:\n",
        "    src = paths[0][query][0]\n",
        "    os.rename(src, f'{folder_name}/{query}/{query}.jpg')\n",
        "\n",
        "#predict based on the image url input \n",
        "def predict_by_url(url):\n",
        "  urllib.request.urlretrieve(url, \"temp.jpg\")\n",
        "  pred,pred_idx,probs = learn_inf.predict(\"temp.jpg\")\n",
        "  print(f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}')\n",
        "\n",
        "  downloadToDisplay(pred, \"Images\")\n",
        "\n",
        "  #Display Image Results\n",
        "  img1=open('temp.jpg','rb').read()\n",
        "  wi1 = widgets.Image(value=img1, format='jpg', width=300, height=400)\n",
        "  file2 = f'Images/{pred}/{pred}.jpg'\n",
        "\n",
        "  #Check if file was successfully downloaded\n",
        "  if os.path.isfile(file2): \n",
        "    img2=open(file2,'rb').read()\n",
        "    wi2 = widgets.Image(value=img2, format='jpg', width=300, height=400)\n",
        "    a=[wi1,wi2]\n",
        "    wid=widgets.HBox(a)\n",
        "    display.display(wid)\n",
        "\n",
        "\n",
        "#get user input\n",
        "while True:\n",
        "  print('Enter a url to predict: (Enter \"quit\" to quit)\\n')\n",
        "  url = str(input())\n",
        "  if url == \"quit\":\n",
        "    break\n",
        "  predict_by_url(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLdXQXHFLxBk"
      },
      "source": [
        ""
      ]
    }
  ]
}